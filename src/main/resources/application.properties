# OceanGPT Application Configuration

# Server Configuration
# [CRITICAL FIX] 动态绑定 Render 提供的端口，如果未提供则使用 8080
server.port=${PORT:8080}
server.servlet.context-path=/api
# [CRITICAL FIX] 强制使用原生代理头处理，识别 HTTPS 协议
server.forward-headers-strategy=native

# Database Configuration
spring.datasource.url=jdbc:h2:mem:testdb
spring.datasource.driverClassName=org.h2.Driver
spring.datasource.username=sa
spring.datasource.password=password
spring.jpa.database-platform=org.hibernate.dialect.H2Dialect
spring.jpa.hibernate.ddl-auto=create-drop
spring.h2.console.enabled=true

# Logging Configuration
logging.level.com.oceangpt=DEBUG
logging.level.org.springframework.web=DEBUG
logging.level.org.springframework.web.socket=DEBUG
logging.level.org.springframework.messaging=DEBUG
logging.pattern.console=%d{yyyy-MM-dd HH:mm:ss} - %msg%n

# Python Model Configuration
# Python executable path (use 'python' for system default, or specify full path)
oceangpt.python.executable=python

# Model path (will be set to target/mymodel if not specified)
oceangpt.model.path=D:/best_model_DIN_heads8_drop0.2.pth

# Enable mock mode for testing (set to true when model file is not available)
oceangpt.model.mock-mode=true

# Model prediction timeout in seconds
oceangpt.model.timeout=30

# OceanGPT vLLM服务配置
oceangpt.vllm.url=http://localhost:8000
oceangpt.vllm.model=OceanGPT-14B-v0.1
oceangpt.vllm.timeout=30000
oceangpt.vllm.max-tokens=2048
oceangpt.vllm.temperature=0.7
oceangpt.vllm.enabled=true

# S2/S3 CSV Data Configuration
oceangpt.data.csv-path=D:/sentinel-2 reflectance

# Satellite Data Service Configuration
# Sentinel-2 API Configuration
oceangpt.satellite.sentinel2.api.url=
oceangpt.satellite.sentinel3.api.url=
oceangpt.satellite.api.key=
oceangpt.satellite.timeout=30000
oceangpt.satellite.mock.enabled=true

# Cache Configuration
spring.cache.type=redis
spring.cache.redis.time-to-live=3600000
spring.cache.cache-names=predictions,trends,reports,satellite-data

# Redis Configuration
spring.data.redis.url=${REDIS_URL:redis://localhost:6379}
spring.session.store-type=redis
spring.session.timeout=3600

# CORS Configuration
oceangpt.cors.allowed-origins=http://localhost:3000,http://localhost:8080
oceangpt.cors.allowed-methods=GET,POST,PUT,DELETE,OPTIONS
oceangpt.cors.allowed-headers=*
oceangpt.cors.allow-credentials=true

# API Rate Limiting
oceangpt.ratelimit.requests-per-minute=100
oceangpt.ratelimit.burst-capacity=20

# Report Generation Configuration
oceangpt.report.default-language=zh-CN
oceangpt.report.max-length=5000
oceangpt.report.include-technical-details=true

# Query Processing Configuration
oceangpt.query.default-language=zh-CN
oceangpt.query.max-response-length=2000
oceangpt.query.confidence-threshold=0.7

# Data Validation
oceangpt.validation.latitude.min=-90.0
oceangpt.validation.latitude.max=90.0
oceangpt.validation.longitude.min=-180.0
oceangpt.validation.longitude.max=180.0
oceangpt.validation.spectral.min=0.0
oceangpt.validation.spectral.max=1.0

# Performance Monitoring
management.endpoints.web.exposure.include=health,info,metrics,prometheus
management.endpoint.health.show-details=always
management.metrics.export.prometheus.enabled=true
